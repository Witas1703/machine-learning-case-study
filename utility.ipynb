{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning case study: rain in Australia dataset\n",
    "### Anna Przybyłowska, Gurbet Gungoren, Wojciech Tomczak, Witold Taisner\n",
    "\n",
    "## 1. Used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "############ MODELS ############################\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#################################################\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing preprocessed data\n",
    "\n",
    "We decided to use one-hot encoding, as it performed slightly better than label-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0     13.4     22.9       0.6          7.0      10.5             44   \n",
       "1      7.4     25.1       0.0          7.6      13.3             44   \n",
       "2     12.9     25.7       0.0         11.4      10.0             46   \n",
       "3      9.2     28.0       0.0          6.8      12.2             24   \n",
       "4     17.5     32.3       1.0          8.0       5.0             41   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
       "0            20            24           71           22  ...               0   \n",
       "1             4            22           44           25  ...               0   \n",
       "2            19            26           38           30  ...               0   \n",
       "3            11             9           45           16  ...               0   \n",
       "4             7            20           82           33  ...               0   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
       "0              0             0              0               0               0   \n",
       "1              0             0              0               0               0   \n",
       "2              0             0              0               0               0   \n",
       "3              0             0              0               0               0   \n",
       "4              1             0              0               0               0   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0              0             0               1               0  \n",
       "1              0             0               0               1  \n",
       "2              0             0               0               1  \n",
       "3              0             0               0               0  \n",
       "4              0             0               0               0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/rain_outliers_removed.csv\")\n",
    "\n",
    "# encoding RainTomorrow and RainToday as binary values\n",
    "df.RainToday.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "df.RainTomorrow.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "\n",
    "#################### ONE-HOT ENCODING #########################################\n",
    "\n",
    "# columns to be changed to one-hot encoding\n",
    "categorical_columns = [\"Season\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]\n",
    "\n",
    "# creating one-hot encoding\n",
    "df = pd.get_dummies(df, columns = categorical_columns)\n",
    "\n",
    "#################### LABEL ENCODER ############################################\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# df[\"Season\"] = le.fit_transform(df[\"Season\"])\n",
    "# df[\"WindDir9am\"]= le.fit_transform(df[\"WindDir9am\"])\n",
    "# df[\"WindDir3pm\"]= le.fit_transform(df[\"WindDir3pm\"])\n",
    "# df[\"WindGustDir\"] = le.fit_transform(df[\"WindGustDir\"])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123710, 70)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.RainTomorrow.to_numpy()\n",
    "X = df.drop(columns=['RainTomorrow']).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Used metrics:\n",
    "Apart from standard accuracy, we decided to also evaluate our models based on [balanced accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html), which is better suited for inbalanced data, as well as F1, Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tested approaches:\n",
    "We decided to test 4 approaches, as our data is quite imbalanced.\n",
    "***\n",
    "### 4.1 Training on preprocessed only dataset\n",
    "We divided our data into two parts, training set consisting of 80% and testing set consisting of 20% of original data.\n",
    "\n",
    "- SVC:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%;\n",
    "- KNN:\n",
    "    - StandardScaler: accuracy: 80%, balanced accuracy: 64%;\n",
    "- MLP Classifier:\n",
    "    - StandardScaler: accuracy: 83%, balanced accuracy: 72%;\n",
    "- Decision Tree Classifier:\n",
    "    - StandardScaler: accuracy: 78%, balanced accuracy: 69%;\n",
    "- **Random Forest Classifier**:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; // 100 estimators\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; // 300 estimators\n",
    "- **AdaBoost Classifier**:\n",
    "    - StandardScaler: accuracy: 84%, balanced accuracy: 71%; // 100 estimators\n",
    "    - StandardScaler: accuracy: 84%, balanced accuracy: 72%; // 300 estimators\n",
    "- **XGBoost Classifier**:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 74%;\n",
    "- Logistic Regression:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72.7%;\n",
    "- **LGBMClassifier**:\n",
    "    - StandardScaler: accuracy: 85.3%, balanced accuracy: 73.5%;\n",
    "    \n",
    "We managed to determine four classifiers, written in bold case, which manged to get the best results on this data.\n",
    "***\n",
    "### 4.2 Oversampling\n",
    "\n",
    "Second of tested approaches focused only on previously found classifiers: *XGBoost*, *Random Forest*, *LGBM* and some of the more promising: *AdaBoost*. \n",
    "Oversampling creates copies of minority class, so that there is even number of each class instance.\n",
    "\n",
    "- **Random Forest Classifier**:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 74.3%; \n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 73.5%;\n",
    "- XGBoost:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 73.8%;\n",
    "- AdaBoost:\n",
    "    - StandardScaler: accuracy: 81.4%, balanced accuracy: 75%;\n",
    "    \n",
    "Easy to notice, oversampling did not improve our results in a significant way."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "count = Counter(y_train)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4.3 Undersampling\n",
    "Similarly to oversampling, we focused on *XGBoost*, *Random Forest*, *LGBM* and *AdaBoost*. Undersampling is a method of removing similar instances of majority class, so that its cardinality is the same as minority class.\n",
    "\n",
    "- **Random Forest Classifier**:\n",
    "    - StandardScaler: accuracy: 79%, balanced accuracy 79%;\n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 79.1%, balanced accuracy: 78.9%;\n",
    "- **XGBoost**:\n",
    "    - StandardScaler: accuracy: 79%, balanced accuracy: 79%;\n",
    "- AdaBoost:\n",
    "    - StandardScaler: accuracy: 78.2%, balanced accuracy: 77.4%;\n",
    "    \n",
    "Undersampling decreases overall accuracy, but at the same time increases balanced accuracy (better prediction of minority class)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "count = Counter(y_train)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 4.4 Feature selection, grid search, class weights\n",
    "In addition we tested some other approaches:\n",
    "        \n",
    "#### 4.4.1 Grid search \n",
    "##### (only for Random Forest and XGBoost)\n",
    "We tried to determine the best parameters for Random Forest and XGBoost with GridSerchCV method connected with K-best feature selection. It managed to determine best parameters and correspodning results:\n",
    "\n",
    "- RandomForest: \n",
    "    - 'criterion': 'entropy',\n",
    "    - 'max_depth': None,\n",
    "    - 'min_samples_leaf': 4,\n",
    "    - 'n_estimators': 100,\n",
    "    - 'feature_selection k': 20\n",
    "    - StandardScaler: **accuracy: 85%, balanced accuracy: 72%**;\n",
    "- XGBoost Classifier:\n",
    "    - 'colsample_bytree': 0.6,\n",
    "    - 'gamma': 0,\n",
    "    - 'max_depth': 8,\n",
    "    - 'min_child_weight': 2,\n",
    "    - 'subsample': 1.0,\n",
    "    - 'feature_selection k': 40}\n",
    "    - StandardScaler: **accuracy: 85.2%, balanced accuracy: 73.6%**;\n",
    "    \n",
    "Grid searches managed to get similar results as training on dataset only.\n",
    "        \n",
    "#### 4.4.2 Class weights\n",
    "In this approach we assigned weights to each class, so that the model would maximize its objective function with minority class having bigger weight.\n",
    "- **XGBoost Classifier**:\n",
    "    - StandardScaler: accuracy: 81%, balanced accuracy 79.4%;\n",
    "- Random Forest Classifier:\n",
    "    - StandardScaler: accuracy: 85.1%, balanced accuracy 71.5%;\n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 80.1%, balanced accuracy: 79.6%;\n",
    "    \n",
    "Assigning weights to classes seems to produce the best trade-off between overall accuracy and balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "#         ('feature_selection', SelectKBest(f_classif, k = 20)) ,\n",
    "#         ('pca', PCA(0.95)),\n",
    "        ('classifier', XGBClassifier(use_label_encoder=False, scale_pos_weight = sum(y_train == 0)/sum(y_train == 1)))\n",
    "\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to be checked by GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "params = {\n",
    "    'feature_selection__k': [10, 20, 40],\n",
    "    # 'pca__n_components': [.8, .85, .9, .95],\n",
    "    #### for Random Forest \n",
    "    # 'classifier__n_estimators': [50, 100, 200, 300, 500],\n",
    "    'classifier__max_depth': [2, 4, 8, None], # also for XGBoost\n",
    "    # 'classifier__min_samples_leaf': [4,8,16],\n",
    "    # 'classifier__criterion': ['gini', 'entropy'],\n",
    "    #### for MLP Classifier\n",
    "    # 'classifier__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    # 'classifier__activation': ['tanh', 'relu'],\n",
    "    # 'classifier__solver': ['sgd', 'adam'],\n",
    "    # 'classifier__alpha': [0.0001, 0.05],\n",
    "    # 'classifier__learning_rate': ['constant','adaptive'],\n",
    "    #### for XGBoost\n",
    "    'classifier__min_child_weight': [1, 2],\n",
    "    'classifier__gamma': [0, 0.5, 1],\n",
    "    'classifier__subsample': [0.6, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 1.0],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, \n",
    "    params, \n",
    "    scoring=\"balanced_accuracy\", \n",
    "    # n_jobs=4, \n",
    "    # verbose=4\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best = grid.best_estimator_\n",
    "y_predicted = best.predict(X_test)\n",
    "metrics.balanced_accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.2s\n",
      "[13:30:14] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   7.9s\n",
      "CPU times: user 1min 30s, sys: 157 ms, total: 1min 30s\n",
      "Wall time: 8.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=3.5120816996443875, subsample=1,\n",
       "                               tree_method='exact', use_label_encoder=False,\n",
       "                               validate_parameters=1, verbosity=None))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     19284\n",
      "           1       0.55      0.77      0.64      5458\n",
      "\n",
      "    accuracy                           0.81     24742\n",
      "   macro avg       0.74      0.79      0.75     24742\n",
      "weighted avg       0.84      0.81      0.82     24742\n",
      "\n",
      "Accuracy of the model is: 80.9514186403686 %\n",
      "Balanced accuracy of the model is: 79.359795406213 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15853,  3431],\n",
       "       [ 1282,  4176]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = metrics.classification_report(y_test, y_predicted)\n",
    "print(report)\n",
    "print(\"Accuracy of the model is:\",metrics.accuracy_score(y_test,y_predicted)*100,\"%\")\n",
    "print(\"Balanced accuracy of the model is:\",metrics.balanced_accuracy_score(y_test, y_predicted)*100,\"%\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
