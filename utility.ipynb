{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, chi2, f_classif\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/rain_outliers_removed.csv\")\n",
    "\n",
    "# encoding RainTomorrow and RainToday as binary values\n",
    "df.RainToday.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "df.RainTomorrow.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "\n",
    "# columns to be changed to one-hot encoding\n",
    "categorical_columns = [\"Season\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]\n",
    "\n",
    "# creating one-hot encoding\n",
    "df = pd.get_dummies(df, columns = categorical_columns)\n",
    "\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.RainTomorrow.to_numpy()\n",
    "X = df.drop(columns=['RainTomorrow']).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "source": [
    "from collections import Counter\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "count = Counter(y_train)\n",
    "print(count)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Counter({0: 77034, 1: 77034})\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## So far tested: \n",
    "### if you're testing some method, please add it here\n",
    "- If not specified, default values of classifiers used\n",
    "### Basic split (20%)\n",
    "- SVC:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%;\n",
    "- KNN:\n",
    "    - StandardScaler: accuracy: 80%, balanced accuracy: 64%;\n",
    "- MLP Classifier:\n",
    "    - StandardScaler: accuracy: 83%, balanced accuracy: 72%;\n",
    "- Decision Tree Classifier:\n",
    "    - StandardScaler: accuracy: 78%, balanced accuracy: 69%;\n",
    "- Random Forest Classifier:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; // 100 estimators\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; // 300 estimators\n",
    "- AdaBoost Classifier:\n",
    "    - StandardScaler: accuracy: 84%, balanced accuracy: 71%; // 100 estimators\n",
    "    - StandardScaler: accuracy: 84%, balanced accuracy: 72%; // 300 estimators\n",
    "- Gausian NB:\n",
    "    - StandardScaler: accuracy: 72%, balanced accuracy: 70%;\n",
    "- QuadraticDiscriminantAnalysis:\n",
    "    - StandardScaler: accuracy: 68%, balanced accuracy: 69%;\n",
    "- XGBoost Classifier:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 74%;\n",
    "- Logistic Regression:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72.7%;\n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 85.3%, balanced accuracy: 73.5%;\n",
    "### Feature selection:\n",
    "- K best (=20):\n",
    "    - XGBoost Classifier:\n",
    "        - StandardScaler: accuracy: 85%, balanced accuracy: 73%;\n",
    "### Grid search\n",
    "- RandomForest: \n",
    "    - 'criterion': 'entropy',\n",
    "    - 'max_depth': None,\n",
    "    - 'min_samples_leaf': 4,\n",
    "    - 'n_estimators': 100,\n",
    "    - 'feature_selection k': 20\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; \n",
    "- XGBoost Classifier\n",
    "    - 'classifier__colsample_bytree': 0.6,\n",
    "    - 'classifier__gamma': 0,\n",
    "    - 'classifier__max_depth': 8,\n",
    "    - 'classifier__min_child_weight': 2,\n",
    "    - 'classifier__subsample': 1.0,\n",
    "    - 'feature_selection__k': 40}\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 73.6%;\n",
    "### Oversampling:\n",
    "- Random Forest Classifier:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 74.3%; \n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 73.5%;\n",
    "\n",
    "\n",
    "## Still to test:\n",
    "- over and under sampling\n",
    "- PCA <- rather useless\n",
    "- fervent prayer\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "pipe = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        # ('feature_selection', SelectKBest(f_classif, k = 20)) ,\n",
    "        # ('pca', PCA(0.95)),\n",
    "        ('classifier', LGBMClassifier())\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) \n",
    "    "
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "source": [
    "params = {\n",
    "    'feature_selection__k': [10, 20, 40],\n",
    "    # 'pca__n_components': [.8, .85, .9, .95],\n",
    "    #### for Random Forest \n",
    "    # 'classifier__n_estimators': [50, 100, 200, 300, 500],\n",
    "    'classifier__max_depth': [2, 4, 8, None], # also for XGBoost\n",
    "    # 'classifier__min_samples_leaf': [4,8,16],\n",
    "    # 'classifier__criterion': ['gini', 'entropy'],\n",
    "    #### for MLP Classifier\n",
    "    # 'classifier__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    # 'classifier__activation': ['tanh', 'relu'],\n",
    "    # 'classifier__solver': ['sgd', 'adam'],\n",
    "    # 'classifier__alpha': [0.0001, 0.05],\n",
    "    # 'classifier__learning_rate': ['constant','adaptive'],\n",
    "    #### for XGBoost\n",
    "    # 'classifier__nthread': [6], ## CHANGE NUMBER OF THREADS YOU WANT TO USE \n",
    "    'classifier__min_child_weight': [1, 2],\n",
    "    'classifier__gamma': [0, 0.5, 1],\n",
    "    'classifier__subsample': [0.6, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 1.0],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, \n",
    "    params, \n",
    "    scoring=\"balanced_accuracy\", \n",
    "    # n_jobs=4, \n",
    "    # verbose=4\n",
    ")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%%time\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_score_\n",
    "grid.best_params_"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "source": [
    "best = grid.best_estimator_\n",
    "y_predicted = best.predict(X_test)\n",
    "metrics.balanced_accuracy_score(y_test, y_predicted)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%%time\n",
    "pipe.fit(X_train, y_train)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.3s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   3.6s\n",
      "CPU times: user 34.3 s, sys: 827 ms, total: 35.1 s\n",
      "Wall time: 3.98 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()), ('classifier', LGBMClassifier())],\n",
       "         verbose=True)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "source": [
    "y_predicted = pipe.predict(X_test)\n",
    "metrics.balanced_accuracy_score(y_test, y_predicted)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.735871888583818"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "source": [
    "report = metrics.classification_report(y_test, y_predicted)\n",
    "print(report)\n",
    "print(\"Accuracy of the model is:\",metrics.accuracy_score(y_test,y_predicted)*100,\"%\")\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "cm"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.88      0.94      0.91     19284\n           1       0.73      0.53      0.61      5458\n\n    accuracy                           0.85     24742\n   macro avg       0.80      0.74      0.76     24742\nweighted avg       0.84      0.85      0.84     24742\n\nAccuracy of the model is: 85.19117290437313 %\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[18195,  1089],\n",
       "       [ 2575,  2883]])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}