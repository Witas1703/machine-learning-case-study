{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQtdgtNHXKzP",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine learning case study: rain in Australia dataset\n",
    "### Anna Przybyłowska, Gurbet Gungoren, Wojciech Tomczak, Witold Taisner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3S46gNZNXKzT",
    "outputId": "86f42505-7334-4546-a879-78fe4c72e918",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from time import perf_counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "############ MODELS ############################\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "#################################################\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKLETBu2XKzU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Importing preprocessed data\n",
    "\n",
    "We decided to use one-hot encoding, as it performed slightly better than label-encoding. Here we are using our preprocessed dataset, without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "0GT4sDYQXKzU",
    "outputId": "66787694-90d2-4c90-dcd3-7c4faa858fe7",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/rain_outliers_removed.csv\")\n",
    "\n",
    "# encoding RainTomorrow and RainToday as binary values\n",
    "df.RainToday.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "df.RainTomorrow.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "\n",
    "#################### ONE-HOT ENCODING #########################################\n",
    "\n",
    "# columns to be changed to one-hot encoding\n",
    "categorical_columns = [\"Season\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]\n",
    "\n",
    "# creating one-hot encoding\n",
    "df = pd.get_dummies(df, columns = categorical_columns)\n",
    "\n",
    "#################### LABEL ENCODER ############################################\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# df[\"Season\"] = le.fit_transform(df[\"Season\"])\n",
    "# df[\"WindDir9am\"]= le.fit_transform(df[\"WindDir9am\"])\n",
    "# df[\"WindDir3pm\"]= le.fit_transform(df[\"WindDir3pm\"])\n",
    "# df[\"WindGustDir\"] = le.fit_transform(df[\"WindGustDir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>WindDir3pm_NNW</th>\n",
       "      <th>WindDir3pm_NW</th>\n",
       "      <th>WindDir3pm_S</th>\n",
       "      <th>WindDir3pm_SE</th>\n",
       "      <th>WindDir3pm_SSE</th>\n",
       "      <th>WindDir3pm_SSW</th>\n",
       "      <th>WindDir3pm_SW</th>\n",
       "      <th>WindDir3pm_W</th>\n",
       "      <th>WindDir3pm_WNW</th>\n",
       "      <th>WindDir3pm_WSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>13.3</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "0     13.4     22.9       0.6          7.0      10.5             44   \n",
       "1      7.4     25.1       0.0          7.6      13.3             44   \n",
       "2     12.9     25.7       0.0         11.4      10.0             46   \n",
       "3      9.2     28.0       0.0          6.8      12.2             24   \n",
       "4     17.5     32.3       1.0          8.0       5.0             41   \n",
       "\n",
       "   WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...  WindDir3pm_NNW  \\\n",
       "0            20            24           71           22  ...               0   \n",
       "1             4            22           44           25  ...               0   \n",
       "2            19            26           38           30  ...               0   \n",
       "3            11             9           45           16  ...               0   \n",
       "4             7            20           82           33  ...               0   \n",
       "\n",
       "   WindDir3pm_NW  WindDir3pm_S  WindDir3pm_SE  WindDir3pm_SSE  WindDir3pm_SSW  \\\n",
       "0              0             0              0               0               0   \n",
       "1              0             0              0               0               0   \n",
       "2              0             0              0               0               0   \n",
       "3              0             0              0               0               0   \n",
       "4              1             0              0               0               0   \n",
       "\n",
       "   WindDir3pm_SW  WindDir3pm_W  WindDir3pm_WNW  WindDir3pm_WSW  \n",
       "0              0             0               1               0  \n",
       "1              0             0               0               1  \n",
       "2              0             0               0               1  \n",
       "3              0             0               0               0  \n",
       "4              0             0               0               0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OaZApFRvXx8B",
    "outputId": "c5956e42-7838-435b-f6e8-86c88cfda0f5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "Rows:123710\n",
      "Colunms:70\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset dimensions:\\nRows:{df.shape[0]}\\nColunms:{df.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSIFzETlZyLZ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We split data to the training set (80%) and test set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "M_Pdz5YDXKzW",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y = df.RainTomorrow.to_numpy()\n",
    "X = df.drop(columns=['RainTomorrow']).to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M9gi7RrXKzW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Used metrics:\n",
    "Apart from standard accuracy, we decided to also evaluate our models based on [balanced accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html), which is better suited for inbalanced data, as well as F1, Precision and Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6smwIqW8XKzX",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Tested approaches:\n",
    "We decided to test 4 approaches, as our data is quite imbalanced. All the results were obtained for the preprocessed dataset without outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 Training on preprocessed only dataset\n",
    "\n",
    "- SVC:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%;\n",
    "- KNN:\n",
    "    - StandardScaler: accuracy: 80%, balanced accuracy: 64%;\n",
    "- MLP Classifier:\n",
    "    - StandardScaler: accuracy: 83%, balanced accuracy: 72%;\n",
    "- Decision Tree Classifier:\n",
    "    - StandardScaler: accuracy: 78%, balanced accuracy: 69%;\n",
    "- **Random Forest Classifier**:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; // 100 estimators\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72%; // 300 estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- AdaBoost Classifier:\n",
    "    - StandardScaler: accuracy: 84%, balanced accuracy: 71%; // 100 estimators\n",
    "    - StandardScaler: accuracy: 84%, balanced accuracy: 72%; // 300 estimators\n",
    "- **XGBoost Classifier**:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 74%;\n",
    "- **Logistic Regression**:\n",
    "    - StandardScaler: accuracy: 85%, balanced accuracy: 72.7%;\n",
    "- **LGBMClassifier**:\n",
    "    - StandardScaler: accuracy: 85.3%, balanced accuracy: 73.5%;\n",
    "    \n",
    "We managed to determine four classifiers, written in bold case, which manged to get the best results on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Oversampling\n",
    "\n",
    "Second of tested approaches focused only on previously found classifiers: *XGBoost*, *Random Forest*, *LGBM* and some of the more promising: *AdaBoost*. \n",
    "Oversampling creates copies of minority class, so that there is even number of each class instance.\n",
    "\n",
    "- **Random Forest Classifier**:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 74.3%; \n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 73.5%;\n",
    "- XGBoost:\n",
    "    - StandardScaler: accuracy: 85.2%, balanced accuracy: 73.8%;\n",
    "- AdaBoost:\n",
    "    - StandardScaler: accuracy: 81.4%, balanced accuracy: 75%;\n",
    "    \n",
    "Easy to notice, oversampling did not improve our results in a significant way."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "MfOfioS-XKzX",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\n",
    "count = Counter(y_train)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc5VY4NfXKzY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.3 Undersampling\n",
    "Similarly to oversampling, we focused on *XGBoost*, *Random Forest*, *LGBM* and *AdaBoost*. Undersampling is a method of removing similar instances of majority class, so that its cardinality is the same as minority class.\n",
    "\n",
    "- **Random Forest Classifier**:\n",
    "    - StandardScaler: accuracy: 79%, balanced accuracy 79%;\n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 79.1%, balanced accuracy: 78.9%;\n",
    "- **XGBoost**:\n",
    "    - StandardScaler: accuracy: 79%, balanced accuracy: 79%;\n",
    "- AdaBoost:\n",
    "    - StandardScaler: accuracy: 78.2%, balanced accuracy: 77.4%;\n",
    "    \n",
    "Undersampling decreases overall accuracy, but at the same time increases balanced accuracy (better prediction of minority class)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "dVUFrZGfXKzY",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_train, y_train = rus.fit_resample(X_train, y_train)\n",
    "count = Counter(y_train)\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T4ygvAeXKzY",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.4 Feature selection, grid search, class weights\n",
    "In addition we tested some other approaches:       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 4.4.1 Grid search \n",
    "##### (only for Random Forest and XGBoost)\n",
    "We tried to determine the best parameters for Random Forest and XGBoost with GridSerchCV method connected with K-best feature selection. It managed to determine best parameters and correspodning results:\n",
    "\n",
    "- RandomForest: \n",
    "    - 'criterion': 'entropy',\n",
    "    - 'max_depth': None,\n",
    "    - 'min_samples_leaf': 4,\n",
    "    - 'n_estimators': 100,\n",
    "    - 'feature_selection k': 20\n",
    "    - StandardScaler: **accuracy: 85%, balanced accuracy: 72%**;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- XGBoost Classifier:\n",
    "    - 'colsample_bytree': 0.6,\n",
    "    - 'gamma': 0,\n",
    "    - 'max_depth': 8,\n",
    "    - 'min_child_weight': 2,\n",
    "    - 'subsample': 1.0,\n",
    "    - 'feature_selection k': 40}\n",
    "    - StandardScaler: **accuracy: 85.2%, balanced accuracy: 73.6%**;\n",
    "    \n",
    "Grid searches managed to get similar results as training on dataset only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 4.4.2 Class weights\n",
    "In this approach we assigned weights to each class, so that the model would maximize its objective function with minority class having bigger weight.\n",
    "- **XGBoost Classifier**:\n",
    "    - StandardScaler: accuracy: 81%, balanced accuracy 79.4%;\n",
    "- Random Forest Classifier:\n",
    "    - StandardScaler: accuracy: 85.1%, balanced accuracy 71.5%;\n",
    "- LGBMClassifier:\n",
    "    - StandardScaler: accuracy: 80.1%, balanced accuracy: 79.6%;\n",
    "    \n",
    "Assigning weights to classes seems to produce the best trade-off between overall accuracy and balanced accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGXj22-CafbC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Choosing the best approches.\n",
    "  We decided to choose 3 classifiers which gave us the best results and check how they perform on the original dataset and the dataset with outliers.\n",
    "\n",
    "  - LGBM Classifier\n",
    "  - Random Forest\n",
    "  - XGBoost Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Iw8yFM4cfcg",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We will test the results with 4 differetn approaches:\n",
    "  - just simple training on training set\n",
    "  - oversampling\n",
    "  - undersampling\n",
    "  - class weights\n",
    "\n",
    "Since grid search is quite expensive when it comes to time, we decided not to check how it performs on the other datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EolbIcNSXKzZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnnPrKDViPxh",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dataset with outliers (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gsKtUCA9iP-Z",
    "outputId": "5b0572f2-b3e1-4e50-e954-a80511ffbe49",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "Rows:123710\n",
      "Colunms:70\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/rain_with_outliers.csv\")\n",
    "\n",
    "# encoding RainTomorrow and RainToday as binary values\n",
    "df1.RainToday.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "df1.RainTomorrow.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "\n",
    "#################### ONE-HOT ENCODING #########################################\n",
    "\n",
    "# columns to be changed to one-hot encoding\n",
    "categorical_columns = [\"Season\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"]\n",
    "\n",
    "# creating one-hot encoding\n",
    "df1 = pd.get_dummies(df1, columns = categorical_columns)\n",
    "\n",
    "#################### LABEL ENCODER ############################################\n",
    "\n",
    "# le = LabelEncoder()\n",
    "\n",
    "# df[\"Season\"] = le.fit_transform(df[\"Season\"])\n",
    "# df[\"WindDir9am\"]= le.fit_transform(df[\"WindDir9am\"])\n",
    "# df[\"WindDir3pm\"]= le.fit_transform(df[\"WindDir3pm\"])\n",
    "# df[\"WindGustDir\"] = le.fit_transform(df[\"WindGustDir\"])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "print(f'Dataset dimensions:\\nRows:{df1.shape[0]}\\nColunms:{df1.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xEwEhhbEj0oy",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y1 = df1.RainTomorrow.to_numpy()\n",
    "X1 = df1.drop(columns=['RainTomorrow']).to_numpy()\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuLlLzDjimP5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Original dataset  - we have to remove all na value to make all the classifiers work, but since we don't want to perform a lot of processing we will use label encoding instead of one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vy2_boQTimgL",
    "outputId": "57e30261-0d4a-411a-d559-e2c6db4dd2e8",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "Rows:56419\n",
      "Colunms:22\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data/weatherAUS_original_data.csv\")\n",
    "df2.drop(df2.index[(df2['Cloud3pm'] > 8) | (df2['Cloud9am'] > 8)], inplace = True)\n",
    "df2.drop(\"Date\", axis = 1, inplace = True)\n",
    "df2.dropna(inplace = True)\n",
    "\n",
    "# encoding RainTomorrow and RainToday as binary values\n",
    "df2.RainToday.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "df2.RainTomorrow.replace((\"Yes\", \"No\"), (1,0), inplace = True)\n",
    "\n",
    "#################### LABEL ENCODER ############################################\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df2[\"Location\"] = le.fit_transform(df2[\"Location\"])\n",
    "df2[\"WindDir9am\"]= le.fit_transform(df2[\"WindDir9am\"])\n",
    "df2[\"WindDir3pm\"]= le.fit_transform(df2[\"WindDir3pm\"])\n",
    "df2[\"WindGustDir\"] = le.fit_transform(df2[\"WindGustDir\"])\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "print(f'Dataset dimensions:\\nRows:{df2.shape[0]}\\nColunms:{df2.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "rWu4EgEUj744",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y2 = df2.RainTomorrow.to_numpy()\n",
    "X2 = df2.drop(columns=['RainTomorrow']).to_numpy()\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-BJmBMqd8Gy",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3sQ0qjQZXKza",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe_LGBM = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LGBMClassifier())\n",
    "\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) \n",
    "\n",
    "pipe_LGBM_weight = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LGBMClassifier(class_weight='balanced'))\n",
    "\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1V8xLAfkLSB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DV0GP9NwkLbq",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe_RF = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) \n",
    "\n",
    "pipe_RF_weight = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', RandomForestClassifier(class_weight='balanced'))\n",
    "\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMoHgPvrkLla",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TwnDXfQjkLvT",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pipe_XGB = Pipeline(\n",
    "    [\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', XGBClassifier())\n",
    "\n",
    "    ], \n",
    "    verbose=True\n",
    "    ) \n",
    "def pipe_XGB_weight(y_train):\n",
    "  pipe_XGB_weight = Pipeline(\n",
    "      [\n",
    "          ('scaler', StandardScaler()),\n",
    "          ('classifier', XGBClassifier(use_label_encoder=False, \n",
    "            scale_pos_weight = sum(y_train == 0)/sum(y_train == 1)))\n",
    "\n",
    "      ], \n",
    "      verbose=True\n",
    "      ) \n",
    "  return pipe_XGB_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NzAVC-8XKzb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Training the models - functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def count_time(func):\n",
    "    def _count(*args, **kwargs):\n",
    "        start = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        stop = perf_counter()\n",
    "        print(f'Total time: {stop - start}')\n",
    "        return result\n",
    "    return _count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PTrxyiv4mxsI",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@count_time\n",
    "def training(pipe, X_train, y_train, X_test):\n",
    "  pipe.fit(X_train, y_train)\n",
    "  y_predicted = pipe.predict(X_test)\n",
    "  return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t5MbTiJUndn2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def report(y_predicted, y_test, data):\n",
    "  report = metrics.classification_report(y_test, y_predicted)\n",
    "  print(data)\n",
    "  print(report)\n",
    "  p1=metrics.accuracy_score(y_test,y_predicted)*100\n",
    "  p2=metrics.balanced_accuracy_score(y_test, y_predicted)*100\n",
    "  print(\"Accuracy of the model is:\",p1,\"%\")\n",
    "  print(\"Balanced accuracy of the model is:\",p2,\"%\")\n",
    "  cm = metrics.confusion_matrix(y_test, y_predicted)\n",
    "  print(cm)\n",
    "  return ((p1,p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "mg-PXgmw2F2k",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyJhO9KX1I6g",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6.1 Simple approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LAFLCbynZ6G",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LGBM (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GU9LeI4jXKzc",
    "outputId": "deb21df8-464a-477e-f9a2-facada9bef50",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.6s\n",
      "Total time: 0.7581365599999117\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     19284\n",
      "           1       0.74      0.52      0.61      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.81      0.74      0.76     24742\n",
      "weighted avg       0.84      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.37304987470698 %\n",
      "Balanced accuracy of the model is: 73.54623289506358 %\n",
      "[[18264  1020]\n",
      " [ 2599  2859]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(simple, no outliers)'] = report(\n",
    "    training(pipe_LGBM, X_train, y_train, X_test), \n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qoOlnYdMplqd",
    "outputId": "87adf4d7-6090-4577-bbb8-7e190d27ddd6",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.7s\n",
      "Total time: 0.7685166970004502\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     19284\n",
      "           1       0.74      0.53      0.62      5458\n",
      "\n",
      "    accuracy                           0.86     24742\n",
      "   macro avg       0.81      0.74      0.77     24742\n",
      "weighted avg       0.85      0.86      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.58321881820386 %\n",
      "Balanced accuracy of the model is: 74.07514219767569 %\n",
      "[[18256  1028]\n",
      " [ 2539  2919]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(simple, outliers)'] = report(\n",
    "    training(pipe_LGBM, X1_train, y1_train, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MBB4t3sypl39",
    "outputId": "9f852b85-7663-4c1b-bdc7-b18228e57cdc",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.3s\n",
      "Total time: 0.36958353800037\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92      8793\n",
      "           1       0.76      0.57      0.65      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.82      0.76      0.78     11284\n",
      "weighted avg       0.86      0.86      0.86     11284\n",
      "\n",
      "Accuracy of the model is: 86.41439205955335 %\n",
      "Balanced accuracy of the model is: 75.81797598843612 %\n",
      "[[8335  458]\n",
      " [1075 1416]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(simple, original)'] = report(\n",
    "    training(pipe_LGBM, X2_train, y2_train, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSCgr_sMXKzd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "XGBoost (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARxbjA00XKzd",
    "outputId": "a269aa7c-775d-45c1-8305-7db814489d42",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[02:25:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   3.9s\n",
      "Total time: 3.991296522999619\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.73      0.54      0.62      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.80      0.74      0.76     24742\n",
      "weighted avg       0.84      0.85      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.33667448064021 %\n",
      "Balanced accuracy of the model is: 74.03520474162258 %\n",
      "[[18177  1107]\n",
      " [ 2521  2937]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(simple, no outliers)'] = report(\n",
    "    training(pipe_XGB, X_train, y_train, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25hPHxX4qZ4b",
    "outputId": "cba329ab-a7c2-4c0e-86fd-9e50ba14f061",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[02:25:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   4.0s\n",
      "Total time: 4.086445136999828\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     19284\n",
      "           1       0.74      0.55      0.63      5458\n",
      "\n",
      "    accuracy                           0.86     24742\n",
      "   macro avg       0.81      0.75      0.77     24742\n",
      "weighted avg       0.85      0.86      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.79742947215261 %\n",
      "Balanced accuracy of the model is: 74.67889278227227 %\n",
      "[[18238  1046]\n",
      " [ 2468  2990]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(simple, outliers)'] = report(\n",
    "    training(pipe_XGB, X1_train, y1_train, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2iW-xX9oqcg_",
    "outputId": "b102bcf4-69d5-4078-f659-9b6d6b0576c4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[02:25:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   1.1s\n",
      "Total time: 1.0986063290001766\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      8793\n",
      "           1       0.74      0.57      0.65      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.81      0.76      0.78     11284\n",
      "weighted avg       0.85      0.86      0.86     11284\n",
      "\n",
      "Accuracy of the model is: 86.19283941864587 %\n",
      "Balanced accuracy of the model is: 75.90599215289451 %\n",
      "[[8294  499]\n",
      " [1059 1432]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(simple, original)'] = report(\n",
    "    training(pipe_XGB, X2_train, y2_train, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM2jKLwrn0-3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Random Forest (simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fLzVvuj_nv7y",
    "outputId": "9bf129d0-b754-4f08-8039-d971cacc3cf9",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  17.2s\n",
      "Total time: 17.85263612000017\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19284\n",
      "           1       0.76      0.49      0.60      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.81      0.72      0.75     24742\n",
      "weighted avg       0.84      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.32859105973648 %\n",
      "Balanced accuracy of the model is: 72.26978391456275 %\n",
      "[[18443   841]\n",
      " [ 2789  2669]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(simple, no outliers)'] = report(\n",
    "    training(pipe_RF, X_train, y_train, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9z_xuINorBOS",
    "outputId": "37b2efde-c31f-4d3b-a06b-570195926cb3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  17.2s\n",
      "Total time: 17.76227094999922\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19284\n",
      "           1       0.76      0.50      0.60      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.82      0.73      0.76     24742\n",
      "weighted avg       0.85      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.49834289871474 %\n",
      "Balanced accuracy of the model is: 72.7070845693185 %\n",
      "[[18435   849]\n",
      " [ 2739  2719]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(simple, outliers)'] = report(\n",
    "    training(pipe_RF, X1_train, y1_train, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K7b0bwxvrBWn",
    "outputId": "493fc882-3628-41df-bcb0-118e220c2413",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   7.9s\n",
      "Total time: 8.144166994999978\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.91      8793\n",
      "           1       0.77      0.53      0.63      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.83      0.74      0.77     11284\n",
      "weighted avg       0.85      0.86      0.85     11284\n",
      "\n",
      "Accuracy of the model is: 86.13966678482808 %\n",
      "Balanced accuracy of the model is: 74.11679201956338 %\n",
      "[[8410  383]\n",
      " [1181 1310]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(simple, original)'] = report(\n",
    "    training(pipe_RF, X2_train, y2_train, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1v6L3jL01Rsz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6.2 Class weight approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr1kUrGprjua",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LGBM (class weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtGhzphorkPf",
    "outputId": "b86aaf79-cae8-47ad-f14a-0ca3df22598e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.8s\n",
      "Total time: 0.8909794690007402\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86     19284\n",
      "           1       0.53      0.79      0.64      5458\n",
      "\n",
      "    accuracy                           0.80     24742\n",
      "   macro avg       0.73      0.80      0.75     24742\n",
      "weighted avg       0.84      0.80      0.81     24742\n",
      "\n",
      "Accuracy of the model is: 80.0945760245736 %\n",
      "Balanced accuracy of the model is: 79.56544171405956 %\n",
      "[[15526  3758]\n",
      " [ 1167  4291]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(weights, no outliers)'] = report(\n",
    "    training(pipe_LGBM_weight, X_train, y_train, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oRSr3OSXrkW3",
    "outputId": "5fcc95c2-30a6-4e62-a5eb-e854b0d51749",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.6s\n",
      "Total time: 0.7623002319996885\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.87     19284\n",
      "           1       0.54      0.79      0.64      5458\n",
      "\n",
      "    accuracy                           0.81     24742\n",
      "   macro avg       0.74      0.80      0.76     24742\n",
      "weighted avg       0.85      0.81      0.82     24742\n",
      "\n",
      "Accuracy of the model is: 80.69274917144936 %\n",
      "Balanced accuracy of the model is: 80.17906098798701 %\n",
      "[[15639  3645]\n",
      " [ 1132  4326]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(weights, outliers)'] = report(\n",
    "    training(pipe_LGBM_weight, X1_train, y1_train, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Chp1iFErkd-",
    "outputId": "05716f75-f912-4b17-b618-1e764011aeae",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.3s\n",
      "Total time: 0.37492626200037193\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.82      0.88      8793\n",
      "           1       0.57      0.81      0.67      2491\n",
      "\n",
      "    accuracy                           0.82     11284\n",
      "   macro avg       0.75      0.82      0.77     11284\n",
      "weighted avg       0.86      0.82      0.83     11284\n",
      "\n",
      "Accuracy of the model is: 82.05423608649414 %\n",
      "Balanced accuracy of the model is: 81.66623317159105 %\n",
      "[[7242 1551]\n",
      " [ 474 2017]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(weights, original)'] = report(\n",
    "    training(pipe_LGBM_weight, X2_train, y2_train, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMipfP3Xrkqf",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "XGBoost (class weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4swaWNY-rk0f",
    "outputId": "97cfc77f-04e6-4518-e4c4-03111af1e1d0",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[02:26:16] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   3.7s\n",
      "Total time: 3.821975509999902\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     19284\n",
      "           1       0.55      0.77      0.64      5458\n",
      "\n",
      "    accuracy                           0.81     24742\n",
      "   macro avg       0.74      0.79      0.75     24742\n",
      "weighted avg       0.84      0.81      0.82     24742\n",
      "\n",
      "Accuracy of the model is: 80.9514186403686 %\n",
      "Balanced accuracy of the model is: 79.359795406213 %\n",
      "[[15853  3431]\n",
      " [ 1282  4176]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(weights, no outliers)'] = report(\n",
    "    training(pipe_XGB_weight(y_train), X_train, y_train, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RhEKy_IHrk6v",
    "outputId": "72f2a299-f986-48cf-fb81-053455b948e5",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[02:26:20] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   3.4s\n",
      "Total time: 3.548556625000856\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     19284\n",
      "           1       0.55      0.77      0.64      5458\n",
      "\n",
      "    accuracy                           0.81     24742\n",
      "   macro avg       0.74      0.80      0.76     24742\n",
      "weighted avg       0.84      0.81      0.82     24742\n",
      "\n",
      "Accuracy of the model is: 81.24242179290275 %\n",
      "Balanced accuracy of the model is: 79.73695187682385 %\n",
      "[[15896  3388]\n",
      " [ 1253  4205]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(weights, outliers)'] = report(\n",
    "    training(pipe_XGB_weight(y1_train), X1_train, y1_train, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guKWsPVXrk_S",
    "outputId": "16eed809-cc65-406c-b889-32fed943e4be",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[02:26:24] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.9s\n",
      "Total time: 0.911173652000798\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      8793\n",
      "           1       0.59      0.77      0.67      2491\n",
      "\n",
      "    accuracy                           0.83     11284\n",
      "   macro avg       0.76      0.81      0.78     11284\n",
      "weighted avg       0.85      0.83      0.84     11284\n",
      "\n",
      "Accuracy of the model is: 83.18858560794044 %\n",
      "Balanced accuracy of the model is: 80.82601973039483 %\n",
      "[[7479 1314]\n",
      " [ 583 1908]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(weights, original)'] = report(\n",
    "    training(pipe_XGB_weight(y2_train), X2_train, y2_train, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0VzpF0MrlNv",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Random Forest (class weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OzER0YGjrlYn",
    "outputId": "70fcf0fa-7b36-4b40-d30e-037a0c2451b5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  15.9s\n",
      "Total time: 16.537422116000016\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91     19284\n",
      "           1       0.76      0.47      0.58      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.81      0.71      0.74     24742\n",
      "weighted avg       0.84      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.03354619675046 %\n",
      "Balanced accuracy of the model is: 71.37772736673536 %\n",
      "[[18477   807]\n",
      " [ 2896  2562]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(weights, no outliers)'] = report(\n",
    "    training(pipe_RF_weight, X_train, y_train, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uakK5xr7rlfP",
    "outputId": "82bcbffa-b657-4c8a-fecb-c1ec6327187c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  16.1s\n",
      "Total time: 16.661805219999223\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91     19284\n",
      "           1       0.77      0.48      0.59      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.82      0.72      0.75     24742\n",
      "weighted avg       0.84      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.25179856115108 %\n",
      "Balanced accuracy of the model is: 71.83300581484039 %\n",
      "[[18483   801]\n",
      " [ 2848  2610]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(weights, outliers)'] = report(\n",
    "    training(pipe_RF_weight, X1_train, y1_train, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QgeHUJVFrlkZ",
    "outputId": "be66222f-01f0-479d-e66c-abbf3b4762c4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   7.5s\n",
      "Total time: 7.737518910998915\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.92      8793\n",
      "           1       0.79      0.51      0.62      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.83      0.74      0.77     11284\n",
      "weighted avg       0.85      0.86      0.85     11284\n",
      "\n",
      "Accuracy of the model is: 86.13080467919177 %\n",
      "Balanced accuracy of the model is: 73.52128301028476 %\n",
      "[[8450  343]\n",
      " [1222 1269]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(weights, original)'] = report(\n",
    "    training(pipe_RF_weight, X2_train, y2_train, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymmBkiwfyLaG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6.3 Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtmYX6J2yLmD",
    "outputId": "93edc642-465d-413c-df1f-f65f5ed770ef",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE() \n",
    "X_traino, y_traino = oversample.fit_resample(X_train, y_train)\n",
    "X1_traino, y1_traino = oversample.fit_resample(X1_train, y1_train) \n",
    "X2_traino, y2_traino = oversample.fit_resample(X2_train, y2_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI7R0HtwxDbQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LGBM (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ye7pIaT3xDx7",
    "outputId": "670b180c-0054-4cb9-e64d-d8658895e3eb",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   1.6s\n",
      "Total time: 1.7330779549993167\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.73      0.53      0.61      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.80      0.74      0.76     24742\n",
      "weighted avg       0.84      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.21946487753618 %\n",
      "Balanced accuracy of the model is: 73.68415512048068 %\n",
      "[[18190  1094]\n",
      " [ 2563  2895]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(oversampling, no outliers)'] = report(\n",
    "    training(pipe_LGBM, X_traino, y_traino, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oELNm0KhxD6h",
    "outputId": "1a62c44e-06d2-4328-c9e5-4bc34bafc0c3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   1.5s\n",
      "Total time: 1.6542812419993425\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.73      0.55      0.62      5458\n",
      "\n",
      "    accuracy                           0.86     24742\n",
      "   macro avg       0.81      0.74      0.77     24742\n",
      "weighted avg       0.85      0.86      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.54280171368524 %\n",
      "Balanced accuracy of the model is: 74.44329647021107 %\n",
      "[[18186  1098]\n",
      " [ 2479  2979]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(oversampling, outliers)'] = report(\n",
    "    training(pipe_LGBM, X1_traino, y1_traino, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MIMWZRGUxEEZ",
    "outputId": "10de33cc-1669-4498-9cfe-b79370c6f485",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.4s\n",
      "Total time: 0.467367954999645\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      8793\n",
      "           1       0.73      0.60      0.66      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.81      0.77      0.79     11284\n",
      "weighted avg       0.86      0.86      0.86     11284\n",
      "\n",
      "Accuracy of the model is: 86.17511520737328 %\n",
      "Balanced accuracy of the model is: 76.75777459379182 %\n",
      "[[8232  561]\n",
      " [ 999 1492]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(oversampling, original)'] = report(\n",
    "    training(pipe_LGBM, X2_traino, y2_traino, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soexRAe4xEUi",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "XGBoost (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfKZOK2-xEdm",
    "outputId": "ab9f9b9c-9111-4971-9066-85732a4e843c",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[02:27:31] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   7.6s\n",
      "Total time: 7.770929865000653\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.72      0.54      0.62      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.80      0.74      0.76     24742\n",
      "weighted avg       0.84      0.85      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.33263277018834 %\n",
      "Balanced accuracy of the model is: 74.19024491983397 %\n",
      "[[18152  1132]\n",
      " [ 2497  2961]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(oversampling, no outliers)'] = report(\n",
    "    training(pipe_XGB, X_traino, y_traino, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OJiPOwbyxElZ",
    "outputId": "e1b293fe-a158-4fd2-95bb-7698ca523f61",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[02:27:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   8.1s\n",
      "Total time: 8.275296193000031\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.73      0.55      0.63      5458\n",
      "\n",
      "    accuracy                           0.86     24742\n",
      "   macro avg       0.81      0.75      0.77     24742\n",
      "weighted avg       0.85      0.86      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.668094737693 %\n",
      "Balanced accuracy of the model is: 74.81923586264412 %\n",
      "[[18172  1112]\n",
      " [ 2434  3024]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(oversampling, outliers)'] = report(\n",
    "    training(pipe_XGB, X1_traino, y1_traino, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srPnMjhhxEqB",
    "outputId": "377f8234-cb18-438f-8df1-1bb966765352",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[02:27:47] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   2.6s\n",
      "Total time: 2.6454684479995194\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      8793\n",
      "           1       0.73      0.59      0.65      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.81      0.77      0.78     11284\n",
      "weighted avg       0.85      0.86      0.86     11284\n",
      "\n",
      "Accuracy of the model is: 86.13080467919177 %\n",
      "Balanced accuracy of the model is: 76.57109778073806 %\n",
      "[[8238  555]\n",
      " [1010 1481]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(oversampling, original)'] = report(\n",
    "    training(pipe_XGB, X2_traino, y2_traino, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqQru0mTxE1S",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Random Forest (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TDVHmfdxFAg",
    "outputId": "ff6ab929-a943-40d4-860c-36be64b6aa68",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  37.0s\n",
      "Total time: 37.714844272000846\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.71      0.55      0.62      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.80      0.74      0.76     24742\n",
      "weighted avg       0.84      0.85      0.84     24742\n",
      "\n",
      "Accuracy of the model is: 85.13054724759517 %\n",
      "Balanced accuracy of the model is: 74.20510068438368 %\n",
      "[[18080  1204]\n",
      " [ 2475  2983]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(oversampling, no outliers)'] = report(\n",
    "    training(pipe_RF, X_traino, y_traino, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCg7qUNnxFHs",
    "outputId": "c174e99e-4b0e-4585-c266-f2f83c74ec45",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.1s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  38.6s\n",
      "Total time: 39.30132561800019\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91     19284\n",
      "           1       0.72      0.56      0.63      5458\n",
      "\n",
      "    accuracy                           0.85     24742\n",
      "   macro avg       0.80      0.75      0.77     24742\n",
      "weighted avg       0.85      0.85      0.85     24742\n",
      "\n",
      "Accuracy of the model is: 85.47813434645542 %\n",
      "Balanced accuracy of the model is: 74.92068659702966 %\n",
      "[[18091  1193]\n",
      " [ 2400  3058]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(oversampling, outliers)'] = report(\n",
    "    training(pipe_RF, X1_traino, y1_traino, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGChnI2txFMP",
    "outputId": "1fddcc1d-e8a4-4952-d41d-609384af985e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=  17.4s\n",
      "Total time: 17.638599116999103\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91      8793\n",
      "           1       0.68      0.66      0.67      2491\n",
      "\n",
      "    accuracy                           0.86     11284\n",
      "   macro avg       0.79      0.78      0.79     11284\n",
      "weighted avg       0.85      0.86      0.86     11284\n",
      "\n",
      "Accuracy of the model is: 85.62566465792271 %\n",
      "Balanced accuracy of the model is: 78.43363596722568 %\n",
      "[[8029  764]\n",
      " [ 858 1633]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(oversampling, original)'] = report(\n",
    "    training(pipe_RF, X2_traino, y2_traino, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PB4GwIpXyRoO",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6.4 Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDlugewTyRxZ",
    "outputId": "3c1b99d2-6c4a-438b-b178-b6181d10c11f",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0) \n",
    "X_trainu, y_trainu = rus.fit_resample(X_train, y_train) \n",
    "X1_trainu, y1_trainu = rus.fit_resample(X1_train, y1_train) \n",
    "X2_trainu, y2_trainu = rus.fit_resample(X2_train, y2_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-KLs1jrxFch",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "LGBM (undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xn4SiSAkxFpM",
    "outputId": "bf970403-0382-4355-9dc8-20cec55e0150",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.4s\n",
      "Total time: 0.5006803970009059\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.86     19284\n",
      "           1       0.52      0.79      0.63      5458\n",
      "\n",
      "    accuracy                           0.79     24742\n",
      "   macro avg       0.73      0.79      0.74     24742\n",
      "weighted avg       0.84      0.79      0.81     24742\n",
      "\n",
      "Accuracy of the model is: 79.26198367148977 %\n",
      "Balanced accuracy of the model is: 79.30060987302939 %\n",
      "[[15279  4005]\n",
      " [ 1126  4332]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(undersampling, no outliers)'] = report(\n",
    "    training(pipe_LGBM, X_trainu, y_trainu, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H2_ECnJaxFwY",
    "outputId": "796853fe-e3ab-4119-b371-329cb938344c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.4s\n",
      "Total time: 0.45632513700002164\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86     19284\n",
      "           1       0.53      0.80      0.64      5458\n",
      "\n",
      "    accuracy                           0.80     24742\n",
      "   macro avg       0.73      0.80      0.75     24742\n",
      "weighted avg       0.84      0.80      0.81     24742\n",
      "\n",
      "Accuracy of the model is: 79.9733247110177 %\n",
      "Balanced accuracy of the model is: 79.88173952527984 %\n",
      "[[15436  3848]\n",
      " [ 1107  4351]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(undersampling, outliers)'] = report(\n",
    "    training(pipe_LGBM, X1_trainu, y1_trainu, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fztsNlAxF4F",
    "outputId": "db4141d6-ff22-497e-a001-9b5dd8464fed",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.2s\n",
      "Total time: 0.22802988399962487\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      8793\n",
      "           1       0.55      0.83      0.66      2491\n",
      "\n",
      "    accuracy                           0.81     11284\n",
      "   macro avg       0.74      0.82      0.76     11284\n",
      "weighted avg       0.86      0.81      0.82     11284\n",
      "\n",
      "Accuracy of the model is: 81.07054236086493 %\n",
      "Balanced accuracy of the model is: 81.61048602445204 %\n",
      "[[7091 1702]\n",
      " [ 434 2057]]\n"
     ]
    }
   ],
   "source": [
    "results['LGBM(undersampling, original)'] = report(\n",
    "    training(pipe_LGBM, X2_trainu, y2_trainu, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6epCDbOqxTSN",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "XGBoost (undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddnhwR99xTe6",
    "outputId": "a1ecf6ac-80a1-44cd-a27b-b3807d83ffb5",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[02:29:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   1.6s\n",
      "Total time: 1.6796609889988758\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.86     19284\n",
      "           1       0.52      0.79      0.63      5458\n",
      "\n",
      "    accuracy                           0.79     24742\n",
      "   macro avg       0.73      0.79      0.74     24742\n",
      "weighted avg       0.84      0.79      0.81     24742\n",
      "\n",
      "Accuracy of the model is: 79.43173551046803 %\n",
      "Balanced accuracy of the model is: 79.45548473383023 %\n",
      "[[15314  3970]\n",
      " [ 1119  4339]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(undersampling, no outliers)'] = report(\n",
    "    training(pipe_XGB, X_trainu, y_trainu, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "USwJ0jgyxTmV",
    "outputId": "e0f5fcdc-9cdd-4f41-f7e7-975a717a93c1",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[02:29:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   1.7s\n",
      "Total time: 1.7715486109991616\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86     19284\n",
      "           1       0.53      0.80      0.63      5458\n",
      "\n",
      "    accuracy                           0.80     24742\n",
      "   macro avg       0.73      0.80      0.75     24742\n",
      "weighted avg       0.84      0.80      0.81     24742\n",
      "\n",
      "Accuracy of the model is: 79.68232155848355 %\n",
      "Balanced accuracy of the model is: 79.76073668174438 %\n",
      "[[15354  3930]\n",
      " [ 1097  4361]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(undersampling, outliers)'] = report(\n",
    "    training(pipe_XGB, X1_trainu, y1_trainu, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRLeLnuNxTtg",
    "outputId": "83ad461c-cc0c-4a52-fd16-edd523947384",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[02:29:30] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   0.5s\n",
      "Total time: 0.5177567480004654\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      8793\n",
      "           1       0.54      0.81      0.65      2491\n",
      "\n",
      "    accuracy                           0.81     11284\n",
      "   macro avg       0.74      0.81      0.76     11284\n",
      "weighted avg       0.85      0.81      0.82     11284\n",
      "\n",
      "Accuracy of the model is: 80.80467919177596 %\n",
      "Balanced accuracy of the model is: 80.9795463829002 %\n",
      "[[7093 1700]\n",
      " [ 466 2025]]\n"
     ]
    }
   ],
   "source": [
    "results['XGB(undersampling, original)'] = report(\n",
    "    training(pipe_XGB, X2_trainu, y2_trainu, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7D1F-9mxT0g",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Random Forest (undersampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mrNTk8uxT8o",
    "outputId": "0f63a399-69c1-4fc8-ad04-bd588f38b40b",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   6.6s\n",
      "Total time: 7.097285071000442\n",
      "Rain outliers removed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.79      0.85     19284\n",
      "           1       0.52      0.78      0.62      5458\n",
      "\n",
      "    accuracy                           0.79     24742\n",
      "   macro avg       0.72      0.79      0.74     24742\n",
      "weighted avg       0.84      0.79      0.80     24742\n",
      "\n",
      "Accuracy of the model is: 79.02352275482984 %\n",
      "Balanced accuracy of the model is: 78.80609514271605 %\n",
      "[[15272  4012]\n",
      " [ 1178  4280]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(undersampling, no outliers)'] = report(\n",
    "    training(pipe_RF, X_trainu, y_trainu, X_test),\n",
    "    y_test, \"Rain outliers removed\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJXWtPFixUDm",
    "outputId": "ad2f20b9-6c0a-43a6-b84b-c3b3477f5ca2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   6.6s\n",
      "Total time: 7.141857091000929\n",
      "Rain with outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86     19284\n",
      "           1       0.53      0.79      0.63      5458\n",
      "\n",
      "    accuracy                           0.80     24742\n",
      "   macro avg       0.73      0.80      0.75     24742\n",
      "weighted avg       0.84      0.80      0.81     24742\n",
      "\n",
      "Accuracy of the model is: 79.8641985288174 %\n",
      "Balanced accuracy of the model is: 79.68037246810685 %\n",
      "[[15429  3855]\n",
      " [ 1127  4331]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(undersampling, outliers)'] = report(\n",
    "    training(pipe_RF, X1_trainu, y1_trainu, X1_test),\n",
    "    y1_test, \"Rain with outliers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXAhGWRIxUH9",
    "outputId": "e1e075c7-2c86-4777-cab9-284de38cfba4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing scaler, total=   0.0s\n",
      "[Pipeline] ........ (step 2 of 2) Processing classifier, total=   3.3s\n",
      "Total time: 3.4563412530005735\n",
      "original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87      8793\n",
      "           1       0.54      0.82      0.65      2491\n",
      "\n",
      "    accuracy                           0.81     11284\n",
      "   macro avg       0.74      0.81      0.76     11284\n",
      "weighted avg       0.85      0.81      0.82     11284\n",
      "\n",
      "Accuracy of the model is: 80.68060971286778 %\n",
      "Balanced accuracy of the model is: 81.10134046538882 %\n",
      "[[7065 1728]\n",
      " [ 452 2039]]\n"
     ]
    }
   ],
   "source": [
    "results['RF(undersampling, original)'] = report(\n",
    "    training(pipe_RF, X2_trainu, y2_trainu, X2_test),\n",
    "    y2_test, \"original data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMP4bPmK042b",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 7. Results - comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SunEAB4oDLSH",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.1 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijs71mEV-VVP",
    "outputId": "6aa606e3-8fb4-4c17-e44d-41cb6c294545",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "outliers = {'acc':{'simple':{}, 'oversampling':{}, 'undersampling':{}, 'weights':{}}, \n",
    "            'balanced':{'simple':{}, 'oversampling':{}, 'undersampling':{}, 'weights':{}}}\n",
    "no_outliers = {'acc':{'simple':{}, 'oversampling':{}, 'undersampling':{}, 'weights':{}}, \n",
    "            'balanced':{'simple':{}, 'oversampling':{}, 'undersampling':{}, 'weights':{}}}\n",
    "original = {'acc':{'simple':{}, 'oversampling':{}, 'undersampling':{}, 'weights':{}}, \n",
    "            'balanced':{'simple':{}, 'oversampling':{}, 'undersampling':{}, 'weights':{}}}\n",
    "for x in results:\n",
    "  t1 = results[x][0]\n",
    "  t2 = results[x][1]\n",
    "  if x.find('LGBM')!=-1:\n",
    "    n='lgbm'\n",
    "  elif x.find('XGB')!=-1:\n",
    "    n='xgb'\n",
    "  else:\n",
    "    n='rf'\n",
    "  if x.find('simple')!=-1:\n",
    "    k='simple'\n",
    "  elif x.find('oversampling')!=-1:\n",
    "    k='oversampling'\n",
    "  elif x.find('undersampling')!=-1:\n",
    "    k='undersampling'\n",
    "  else:\n",
    "    k='weights'\n",
    "  if x.find('no outliers')!=-1:\n",
    "    no_outliers['acc'][k][n]=t1\n",
    "    no_outliers['balanced'][k][n]=t2\n",
    "  elif x.find('outliers')!=-1:\n",
    "    outliers['acc'][k][n]=t1\n",
    "    outliers['balanced'][k][n]=t2\n",
    "  else:\n",
    "    original['acc'][k][n]=t1\n",
    "    original['balanced'][k][n]=t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "mdzylYJXHhTr",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def transform(dict):\n",
    "  return pd.DataFrame.from_dict({(i,j): dict[i][j] \n",
    "                           for i in dict.keys() \n",
    "                           for j in dict[i].keys()},\n",
    "                       orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHKiel9J8C8t",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7.2 Accuracy and balanced accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 936
    },
    "id": "OXOJfNs_LFTW",
    "outputId": "db90a8f2-0b12-455c-bf07-df5c4e22792e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rain with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">acc</th>\n",
       "      <th>simple</th>\n",
       "      <td>85.583219</td>\n",
       "      <td>85.797429</td>\n",
       "      <td>85.498343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>85.542802</td>\n",
       "      <td>85.668095</td>\n",
       "      <td>85.478134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>79.973325</td>\n",
       "      <td>79.682322</td>\n",
       "      <td>79.864199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>80.692749</td>\n",
       "      <td>81.242422</td>\n",
       "      <td>85.251799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">balanced</th>\n",
       "      <th>simple</th>\n",
       "      <td>74.075142</td>\n",
       "      <td>74.678893</td>\n",
       "      <td>72.707085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>74.443296</td>\n",
       "      <td>74.819236</td>\n",
       "      <td>74.920687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>79.881740</td>\n",
       "      <td>79.760737</td>\n",
       "      <td>79.680372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>80.179061</td>\n",
       "      <td>79.736952</td>\n",
       "      <td>71.833006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             lgbm        xgb         rf\n",
       "acc      simple         85.583219  85.797429  85.498343\n",
       "         oversampling   85.542802  85.668095  85.478134\n",
       "         undersampling  79.973325  79.682322  79.864199\n",
       "         weights        80.692749  81.242422  85.251799\n",
       "balanced simple         74.075142  74.678893  72.707085\n",
       "         oversampling   74.443296  74.819236  74.920687\n",
       "         undersampling  79.881740  79.760737  79.680372\n",
       "         weights        80.179061  79.736952  71.833006"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transform(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Rain outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">acc</th>\n",
       "      <th>simple</th>\n",
       "      <td>85.373050</td>\n",
       "      <td>85.336674</td>\n",
       "      <td>85.328591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>85.219465</td>\n",
       "      <td>85.332633</td>\n",
       "      <td>85.130547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>79.261984</td>\n",
       "      <td>79.431736</td>\n",
       "      <td>79.023523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>80.094576</td>\n",
       "      <td>80.951419</td>\n",
       "      <td>85.033546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">balanced</th>\n",
       "      <th>simple</th>\n",
       "      <td>73.546233</td>\n",
       "      <td>74.035205</td>\n",
       "      <td>72.269784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>73.684155</td>\n",
       "      <td>74.190245</td>\n",
       "      <td>74.205101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>79.300610</td>\n",
       "      <td>79.455485</td>\n",
       "      <td>78.806095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>79.565442</td>\n",
       "      <td>79.359795</td>\n",
       "      <td>71.377727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             lgbm        xgb         rf\n",
       "acc      simple         85.373050  85.336674  85.328591\n",
       "         oversampling   85.219465  85.332633  85.130547\n",
       "         undersampling  79.261984  79.431736  79.023523\n",
       "         weights        80.094576  80.951419  85.033546\n",
       "balanced simple         73.546233  74.035205  72.269784\n",
       "         oversampling   73.684155  74.190245  74.205101\n",
       "         undersampling  79.300610  79.455485  78.806095\n",
       "         weights        79.565442  79.359795  71.377727"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transform(no_outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">acc</th>\n",
       "      <th>simple</th>\n",
       "      <td>86.414392</td>\n",
       "      <td>86.192839</td>\n",
       "      <td>86.139667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>86.175115</td>\n",
       "      <td>86.130805</td>\n",
       "      <td>85.625665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>81.070542</td>\n",
       "      <td>80.804679</td>\n",
       "      <td>80.680610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>82.054236</td>\n",
       "      <td>83.188586</td>\n",
       "      <td>86.130805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">balanced</th>\n",
       "      <th>simple</th>\n",
       "      <td>75.817976</td>\n",
       "      <td>75.905992</td>\n",
       "      <td>74.116792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oversampling</th>\n",
       "      <td>76.757775</td>\n",
       "      <td>76.571098</td>\n",
       "      <td>78.433636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>undersampling</th>\n",
       "      <td>81.610486</td>\n",
       "      <td>80.979546</td>\n",
       "      <td>81.101340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights</th>\n",
       "      <td>81.666233</td>\n",
       "      <td>80.826020</td>\n",
       "      <td>73.521283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             lgbm        xgb         rf\n",
       "acc      simple         86.414392  86.192839  86.139667\n",
       "         oversampling   86.175115  86.130805  85.625665\n",
       "         undersampling  81.070542  80.804679  80.680610\n",
       "         weights        82.054236  83.188586  86.130805\n",
       "balanced simple         75.817976  75.905992  74.116792\n",
       "         oversampling   76.757775  76.571098  78.433636\n",
       "         undersampling  81.610486  80.979546  81.101340\n",
       "         weights        81.666233  80.826020  73.521283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(transform(original))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [
    "WyJhO9KX1I6g",
    "1v6L3jL01Rsz",
    "ymmBkiwfyLaG",
    "PB4GwIpXyRoO",
    "SunEAB4oDLSH"
   ],
   "name": "utility.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
